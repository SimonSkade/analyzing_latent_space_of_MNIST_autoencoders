{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T18:17:13.331189Z","iopub.execute_input":"2022-01-24T18:17:13.331578Z","iopub.status.idle":"2022-01-24T18:17:15.057829Z","shell.execute_reply.started":"2022-01-24T18:17:13.331469Z","shell.execute_reply":"2022-01-24T18:17:15.057062Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:17:15.059356Z","iopub.execute_input":"2022-01-24T18:17:15.059626Z","iopub.status.idle":"2022-01-24T18:17:15.063289Z","shell.execute_reply.started":"2022-01-24T18:17:15.059589Z","shell.execute_reply":"2022-01-24T18:17:15.062642Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Training settings\nbatch_size = 64\n\n# MNIST Dataset\ntrain_dataset = datasets.MNIST(root='./data/',\n                               train=True,\n                               transform=transforms.ToTensor(),\n                               download=True)\n\ntest_dataset = datasets.MNIST(root='./data/',\n                              train=False,\n                              transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:17:15.064553Z","iopub.execute_input":"2022-01-24T18:17:15.065321Z","iopub.status.idle":"2022-01-24T18:17:17.193965Z","shell.execute_reply.started":"2022-01-24T18:17:15.065285Z","shell.execute_reply":"2022-01-24T18:17:17.193163Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Data Loader (Input Pipeline)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:17:17.196175Z","iopub.execute_input":"2022-01-24T18:17:17.196647Z","iopub.status.idle":"2022-01-24T18:17:17.202546Z","shell.execute_reply.started":"2022-01-24T18:17:17.196607Z","shell.execute_reply":"2022-01-24T18:17:17.201567Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# visualize an image\nimgs, labels = next(iter(train_loader))\nplt.figure(figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(imgs[i].reshape(28, 28), cmap=plt.cm.binary)\n    plt.xlabel(labels[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:17:17.203793Z","iopub.execute_input":"2022-01-24T18:17:17.204204Z","iopub.status.idle":"2022-01-24T18:17:18.368261Z","shell.execute_reply.started":"2022-01-24T18:17:17.204162Z","shell.execute_reply":"2022-01-24T18:17:18.366984Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def plot_subplot(img, idx, h=5, w=4, label=None):\n    plt.subplot(h, w, idx)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(img, cmap=plt.cm.binary)\n    if label:\n        plt.xlabel(label)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:17:18.372168Z","iopub.execute_input":"2022-01-24T18:17:18.372441Z","iopub.status.idle":"2022-01-24T18:17:18.381057Z","shell.execute_reply.started":"2022-01-24T18:17:18.372401Z","shell.execute_reply":"2022-01-24T18:17:18.380324Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# visualize some results    \ndef test(model):\n    imgs, labels = next(iter(test_loader))\n    results = model(Variable(imgs.view(-1,28*28).to(device))).cpu().detach().numpy()\n    plt.figure(figsize=(10, 10))\n    for i in range(10):\n        # normal image\n        j = np.random.randint(64)\n        plot_subplot(imgs[j].reshape(28, 28), 2*i+1, label=labels[j])\n        # after autoenc\n        plot_subplot(results[j].reshape(28, 28), 2*i+2, label=labels[j])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:22:15.544200Z","iopub.execute_input":"2022-01-24T18:22:15.544461Z","iopub.status.idle":"2022-01-24T18:22:15.550695Z","shell.execute_reply.started":"2022-01-24T18:22:15.544431Z","shell.execute_reply":"2022-01-24T18:22:15.550010Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# define a class autoencoder, with the following amounts of neurons for the layers: 28*28 -> h1 -> h2 -> latSize -> h2 -> h1 -> 28*28, where h1,h2 and latSize are variables\nclass Autoencoder(nn.Module):\n    def __init__(self, h1=128, h2=48, h3=12, latSz=3):\n        super(Autoencoder, self).__init__()\n        self.latSz = latSz\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, h1),\n            nn.Sigmoid(),\n            nn.Linear(h1,h2),\n            nn.Sigmoid(),\n            nn.Linear(h2,h3),\n            nn.Sigmoid(),\n            nn.Linear(h3, latSz),\n            nn.Sigmoid()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(latSz, h3),\n            nn.Sigmoid(),\n            nn.Linear(h3, h2),\n            nn.Sigmoid(),\n            nn.Linear(h2,h1),\n            nn.Sigmoid(),\n            nn.Linear(h1,28*28),\n            nn.Sigmoid()\n        )\n    def forward(self,X,print_lat_space=False):\n        X = self.encoder(X)\n        if print_lat_space:\n            print(X.numpy())\n        return self.decoder(X)\n    \n    def plot_latSpace(self):\n        lat_inputs = torch.FloatTensor(np.eye(self.latSz)).to(device)\n        outs = self.decoder(lat_inputs).cpu().detach().numpy()\n        w = 4\n        h = (self.latSz+w-1)//w\n        plt.figure(figsize=(10, 10))\n        for i in range(self.latSz):\n            plot_subplot(outs[i].reshape(28,28), i+1, h, w)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:31:42.508027Z","iopub.execute_input":"2022-01-24T19:31:42.508297Z","iopub.status.idle":"2022-01-24T19:31:42.519672Z","shell.execute_reply.started":"2022-01-24T19:31:42.508265Z","shell.execute_reply":"2022-01-24T19:31:42.518866Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder().to(device)\ncriterion = nn.MSELoss()\noptim = torch.optim.Adam(model.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:31:47.612403Z","iopub.execute_input":"2022-01-24T19:31:47.612991Z","iopub.status.idle":"2022-01-24T19:31:47.624954Z","shell.execute_reply.started":"2022-01-24T19:31:47.612951Z","shell.execute_reply":"2022-01-24T19:31:47.624181Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def train(model, optim, epochs=20):\n    losses = []\n    for epoch in range(1,1+epochs):\n        losses2 = []\n        for i, (images, _) in enumerate(train_loader):\n            inputImgs = Variable(images.view(-1,28*28).to(device))\n            outputs = model(inputImgs)\n            loss = criterion(inputImgs, outputs)\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n            losses2.append(loss.item())\n        losses.append(np.mean(losses2))\n        print(f\"Epoch {epoch}: Train Loss: {np.mean(losses2)}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:31:48.238994Z","iopub.execute_input":"2022-01-24T19:31:48.239248Z","iopub.status.idle":"2022-01-24T19:31:48.245933Z","shell.execute_reply.started":"2022-01-24T19:31:48.239217Z","shell.execute_reply":"2022-01-24T19:31:48.244924Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# for visualizing epoch by epoch how the result looks like\ntest(model)\ntrain(model, optim, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:31:48.644983Z","iopub.execute_input":"2022-01-24T19:31:48.645741Z","iopub.status.idle":"2022-01-24T19:31:56.959032Z","shell.execute_reply.started":"2022-01-24T19:31:48.645689Z","shell.execute_reply":"2022-01-24T19:31:56.958191Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"train(model, optim, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:31:56.960744Z","iopub.execute_input":"2022-01-24T19:31:56.961085Z","iopub.status.idle":"2022-01-24T19:34:23.944836Z","shell.execute_reply.started":"2022-01-24T19:31:56.961045Z","shell.execute_reply":"2022-01-24T19:34:23.944026Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"test(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:51:24.187344Z","iopub.execute_input":"2022-01-24T19:51:24.187645Z","iopub.status.idle":"2022-01-24T19:51:24.851850Z","shell.execute_reply.started":"2022-01-24T19:51:24.187612Z","shell.execute_reply":"2022-01-24T19:51:24.851031Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model.plot_latSpace()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:34:24.757635Z","iopub.execute_input":"2022-01-24T19:34:24.758035Z","iopub.status.idle":"2022-01-24T19:34:24.875011Z","shell.execute_reply.started":"2022-01-24T19:34:24.757996Z","shell.execute_reply":"2022-01-24T19:34:24.874332Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def print_latent_vectors(model):\n    imgs, labels = next(iter(test_loader))\n    for i in range(10):\n        # normal image\n        j = np.random.randint(64)\n        #result = model(Variable(imgs[j].view(-1,28*28).to(device)), print_lat_space=True).cpu().detach().numpy()\n        lat_vec = model.encoder(Variable(imgs[j].view(-1,28*28).to(device)))\n        print(lat_vec.cpu().detach().numpy())\n        result = model.decoder(Variable(lat_vec).to(device)).cpu().detach().numpy()\n        plt.imshow(result.reshape(28, 28), cmap=\"gray\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:39:28.055124Z","iopub.execute_input":"2022-01-24T19:39:28.055386Z","iopub.status.idle":"2022-01-24T19:39:28.062135Z","shell.execute_reply.started":"2022-01-24T19:39:28.055356Z","shell.execute_reply":"2022-01-24T19:39:28.061331Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"print_latent_vectors(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:45:53.772052Z","iopub.execute_input":"2022-01-24T19:45:53.772321Z","iopub.status.idle":"2022-01-24T19:45:55.437206Z","shell.execute_reply.started":"2022-01-24T19:45:53.772289Z","shell.execute_reply":"2022-01-24T19:45:55.436372Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def plot_lat_detailed(model):\n    inputs = np.array([(1,1,1),(2,1,0),(2,0,1),(1,2,0),(1,0,2),(0,2,1),(0,1,2),(3,0,0),(0,3,0),(0,0,3)])\n    imputs = inputs/3\n    lat_inputs = torch.FloatTensor(inputs).to(device)\n    outs = model.decoder(lat_inputs).cpu().detach().numpy()\n    w = 4\n    n = inputs.shape[0]\n    h = (n+w-1)//w\n    plt.figure(figsize=(10, 10))\n    for i in range(n):\n        plot_subplot(outs[i].reshape(28,28), i+1, h, w, label=np.array2string(inputs[i]))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:05:42.576202Z","iopub.execute_input":"2022-01-24T20:05:42.576472Z","iopub.status.idle":"2022-01-24T20:05:42.585291Z","shell.execute_reply.started":"2022-01-24T20:05:42.576442Z","shell.execute_reply":"2022-01-24T20:05:42.584544Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"plot_lat_detailed(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:05:42.976324Z","iopub.execute_input":"2022-01-24T20:05:42.976874Z","iopub.status.idle":"2022-01-24T20:05:43.384872Z","shell.execute_reply.started":"2022-01-24T20:05:42.976835Z","shell.execute_reply":"2022-01-24T20:05:43.384191Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try different models\nhyperparams = [\n    (128,64,32,16),\n    (128,64,24,12),\n    (128,48,16,10),\n    (128,48,16,8),\n    (128,48,16,6),\n    (128,48,12,4),\n    (128,48,12,3)\n]\nmodels = []\nfor hyps in hyperparams:\n    print(hyps)\n    model = Autoencoder(hyps[0], hyps[1], hyps[2], hyps[3]).to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=0.005)\n    train(model, optim, epochs=15)\n    test(model)\n    model.plot_latSpace()\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:32:06.783830Z","iopub.execute_input":"2022-01-24T20:32:06.784401Z","iopub.status.idle":"2022-01-24T20:45:08.405550Z","shell.execute_reply.started":"2022-01-24T20:32:06.784353Z","shell.execute_reply":"2022-01-24T20:45:08.404717Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoencoders with Sigmoid functions in every layer have significantly worse performance, but are much more interpretable\n# (here is an autoencoder with ReLU, I had done some tests with it, but I didn't run them again to include them here)\nclass Autoencoder(nn.Module):\n    def __init__(self, h1=128, h2=32, latSz=10):\n        super(Autoencoder, self).__init__()\n        self.latSz = latSz\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, h1),\n            nn.ReLU(True),\n            nn.Linear(h1,h2),\n            nn.ReLU(True),\n            nn.Linear(h2, latSz)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(latSz, h2),\n            nn.ReLU(True),\n            nn.Linear(h2,h1),\n            nn.ReLU(True),\n            nn.Linear(h1,28*28),\n            nn.Sigmoid()\n        )\n    def forward(self,X,print_lat_space=False):\n        X = self.encoder(X)\n        if print_lat_space:\n            print(X)\n        return self.decoder(X)\n    \n    def plot_latSpace(self):\n        lat_inputs = torch.FloatTensor(np.eye(self.latSz)).to(device)\n        outs = self.decoder(lat_inputs).cpu().detach().numpy()\n        w = 4\n        h = (self.latSz+w-1)//w\n        plt.figure(figsize=(10, 10))\n        for i in range(self.latSz):\n            plot_subplot(outs[i].reshape(28,28), i+1, h, w)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T11:21:26.482123Z","iopub.execute_input":"2022-01-24T11:21:26.48241Z","iopub.status.idle":"2022-01-24T11:21:26.491956Z","shell.execute_reply.started":"2022-01-24T11:21:26.482369Z","shell.execute_reply":"2022-01-24T11:21:26.491294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}